{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SEMANTIC SEARCH IN ARTICLES USING NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### This notebook implements and compares three different search approaches:\n",
        "### 1. Lexical Search (BM25) - Traditional keyword-based retrieval\n",
        "### 2. Semantic Search (spaCy) - Word embeddings-based search\n",
        "### 3. Semantic Search (Transformers) - BERT-based contextual embeddings\n",
        "###\n",
        "### The system also extracts hot keywords using YAKE and KeyBERT algorithms\n",
        "### It also provide and approach to evaluate differenct models\n",
        "### ============================================================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC5UZXlfgnob"
      },
      "source": [
        "## DATA PREPARATION\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- BBC News Articles Dataset (2004â€“2005)\n",
        "- The BBC News Articles Dataset is a collection of 2,225 news documents published by the BBC between 2004 and 2005.\n",
        "- It covers five major categories: Business, Entertainment, Sport, Tech, Politics\n",
        "\n",
        "- Each document contains the full text of a BBC news article, making it well-suited for information retrieval, keyword extraction, and semantic search tasks.\n",
        "\n",
        "- It is publicly available through the BBC News Summary dataset on Kaggle [dataset link](https://www.kaggle.com/datasets/pariza/bbc-news-summary), originally compiled for text summarization and classification research."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 2225 articles across 5 categories.\n",
            "Saved to: ../data/processed/articles.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>business</td>\n",
              "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>business</td>\n",
              "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>business</td>\n",
              "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>business</td>\n",
              "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>business</td>\n",
              "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  category                                               text\n",
              "0   0  business  Ad sales boost Time Warner profit\\n\\nQuarterly...\n",
              "1   1  business  Dollar gains on Greenspan speech\\n\\nThe dollar...\n",
              "2   2  business  Yukos unit buyer faces loan claim\\n\\nThe owner...\n",
              "3   3  business  High fuel prices hit BA's profits\\n\\nBritish A...\n",
              "4   4  business  Pernod takeover talk lifts Domecq\\n\\nShares in..."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define paths\n",
        "base_dir = \"../data/raw/NewsArticles\"\n",
        "output_path = \"../data/processed/articles.csv\"\n",
        "\n",
        "data = []\n",
        "article_id = 0\n",
        "\n",
        "# Check base directory\n",
        "if not os.path.exists(base_dir):\n",
        "    raise FileNotFoundError(f\"Directory not found: {base_dir}\")\n",
        "\n",
        "# Loop through categories and articles\n",
        "for category in os.listdir(base_dir):\n",
        "    category_path = os.path.join(base_dir, category)\n",
        "    if not os.path.isdir(category_path):\n",
        "        continue\n",
        "\n",
        "    for filename in os.listdir(category_path):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            file_path = os.path.join(category_path, filename)\n",
        "            try:\n",
        "                with open(file_path, \"r\", encoding=\"latin1\") as f:\n",
        "                    text = f.read().strip()\n",
        "                data.append({\n",
        "                    \"id\": article_id,\n",
        "                    \"category\": category,\n",
        "                    \"text\": text\n",
        "                })\n",
        "                article_id += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to read {file_path}: {e}\")\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "\n",
        "# Save combined dataset\n",
        "df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "# Display preview\n",
        "print(f\"Loaded {len(df)} articles across {df['category'].nunique()} categories.\")\n",
        "print(f\"Saved to: {output_path}\")\n",
        "display(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the processed articles dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "data =pd.read_csv(\"../data/processed/articles.csv\")\n",
        "df=data.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display category distribution to understand dataset composition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "vwNn4LkZIp02",
        "outputId": "91a1e8e2-e3a3-4a72-cb74-92c3db59c6e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "category\n",
              "sport            511\n",
              "business         510\n",
              "politics         417\n",
              "tech             401\n",
              "entertainment    386\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['category'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\n+', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text.strip()\n",
        "\n",
        "df['text'] = data['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verify cleaned data structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AY8pWysYJp9n",
        "outputId": "c771a690-5be2-442b-a8dc-ec4038d4b210"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>business</td>\n",
              "      <td>ad sales boost time warner profit quarterly pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>business</td>\n",
              "      <td>dollar gains on greenspan speech the dollar ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>business</td>\n",
              "      <td>yukos unit buyer faces loan claim the owners o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>business</td>\n",
              "      <td>high fuel prices hit bas profits british airwa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>business</td>\n",
              "      <td>pernod takeover talk lifts domecq shares in uk...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  category                                               text\n",
              "0   0  business  ad sales boost time warner profit quarterly pr...\n",
              "1   1  business  dollar gains on greenspan speech the dollar ha...\n",
              "2   2  business  yukos unit buyer faces loan claim the owners o...\n",
              "3   3  business  high fuel prices hit bas profits british airwa...\n",
              "4   4  business  pernod takeover talk lifts domecq shares in uk..."
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynhl9rQujwya"
      },
      "source": [
        "## HOT KEYWORDS EXTRACTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Extract important keywords from articles using two different algorithms:\n",
        " - YAKE: Statistical approach based on word frequency and position\n",
        " - KeyBERT: Transformer-based approach using semantic similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F05BP5ASj1oF"
      },
      "source": [
        "### 1: YAKE (Yet Another Keyword Extractor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "T4-0Q7IJkTUa"
      },
      "outputs": [],
      "source": [
        "import yake\n",
        "def extract_hot_keywords_yake(text, top_n=10):\n",
        "    \"\"\"\n",
        "    Extract hot keywords using YAKE algorithm.\n",
        "    \n",
        "    YAKE is an unsupervised keyword extraction method that uses:\n",
        "    - Word frequency\n",
        "    - Word position\n",
        "    - Word context\n",
        "    - Word case information\n",
        "    \n",
        "    Args:\n",
        "        text (str): Input article text\n",
        "        top_n (int): Number of keywords to extract (default: 10)\n",
        "        \n",
        "    Returns:\n",
        "        list: List of (keyword, score) tuples, lower scores = more important\n",
        "    \"\"\"\n",
        "    kw_extractor = yake.KeywordExtractor(\n",
        "        lan=\"en\",                    # Language: English\n",
        "        n=3,                         # Max n-gram size (1-3 word phrases)\n",
        "        dedupLim=0.9,                # Deduplication threshold (0.9 = high similarity)\n",
        "        dedupFunc='seqm',            # Sequence matcher for deduplication\n",
        "        windowsSize=1,               # Context window size\n",
        "        top=top_n,                   # Number of keywords to return\n",
        "        features=None\n",
        "    )\n",
        "    \n",
        "    keywords = kw_extractor.extract_keywords(text)\n",
        "    return keywords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract keywords for all articles using YAKE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XP_KwcQSkeiE"
      },
      "outputs": [],
      "source": [
        "yake_hot_keywords_df = pd.DataFrame({\n",
        "    'id': df['id'],\n",
        "    'hot_keywords': df['text'].apply(\n",
        "        lambda text: [kw[0] for kw in extract_hot_keywords_yake(text, top_n=10)]\n",
        "    )\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_id</th>\n",
              "      <th>hot_keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[fourth quarter profits, warners fourth quarte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[current account deficit, federal reserve head...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[owner menatep group, case menatep groups, men...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[high fuel prices, blamed high fuel, fuel cost...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[allied domecq shares, lifts domecq shares, al...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   article_id                                       hot_keywords\n",
              "0           0  [fourth quarter profits, warners fourth quarte...\n",
              "1           1  [current account deficit, federal reserve head...\n",
              "2           2  [owner menatep group, case menatep groups, men...\n",
              "3           3  [high fuel prices, blamed high fuel, fuel cost...\n",
              "4           4  [allied domecq shares, lifts domecq shares, al..."
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yake_hot_keywords_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save YAKE keywords to JSON for later use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "yake_hot_keywords_df.to_json(\n",
        "    '../data/hot_keywords/yake_hot_keywords.json', \n",
        "    orient='records',\n",
        "    indent=2,\n",
        "    force_ascii=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNiVyb9vj7vK"
      },
      "source": [
        "### 2: KeyBERT (Transformer-based Keyword Extraction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize KeyBERT with pre-trained sentence transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "6H4-tna7ZZwA"
      },
      "outputs": [],
      "source": [
        "from keybert import KeyBERT\n",
        "kw_model = KeyBERT(model='all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "j9pxIDY1Za8v"
      },
      "outputs": [],
      "source": [
        "def extract_hot_keywords_keybert(text, top_n=10):\n",
        "    \"\"\"\n",
        "    Extract keywords using KeyBERT (transformer-based approach).\n",
        "    \n",
        "    KeyBERT uses BERT embeddings to find words/phrases most similar \n",
        "    to the document, providing semantically relevant keywords.\n",
        "    \n",
        "    Args:\n",
        "        text (str): Input article text\n",
        "        top_n (int): Number of keywords to extract\n",
        "        \n",
        "    Returns:\n",
        "        list: List of (keyword, score) tuples with similarity scores\n",
        "    \"\"\"\n",
        "    keywords = kw_model.extract_keywords(\n",
        "        text,\n",
        "        keyphrase_ngram_range=(1, 3),   # Extract 1-3 word phrases\n",
        "        stop_words='english',            # Remove English stop words\n",
        "        top_n=top_n\n",
        "    )\n",
        "    return keywords\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract keywords for all articles using KeyBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bert_hot_keywords_df = pd.DataFrame({\n",
        "    'id': df['id'],\n",
        "    'hot_keywords': df['text'].apply(\n",
        "        lambda text: [kw[0] for kw in extract_hot_keywords_yake(text, top_n=10)]\n",
        "    )\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save KeyBERT keywords to JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "bert_hot_keywords_df.to_json(\n",
        "    '../data/hot_keywords/Keybert_hot_keywords.json', \n",
        "    orient='records',\n",
        "    indent=2,\n",
        "    force_ascii=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSzutclWhzp4"
      },
      "source": [
        "## LEXICAL SEARCH (BM25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- BM25 is a probabilistic ranking function used by search engines.\n",
        "- It scores documents based on term frequency and inverse document frequency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download spaCy language model for text processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XfQtAG3JVlSu"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from contractions import fix\n",
        "import os\n",
        "import pickle\n",
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load spaCy model (disable unnecessary components for speed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "juYZauKIJuVw"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Complete preprocessing pipeline for lexical search.\n",
        "    \n",
        "    Pipeline:\n",
        "    1. Lowercase conversion\n",
        "    2. Contraction expansion (e.g., \"don't\" -> \"do not\")\n",
        "    3. Tokenization using spaCy\n",
        "    4. Remove stop words and short tokens (< 3 chars)\n",
        "    5. Lemmatization (convert words to base form)\n",
        "    \n",
        "    Args:\n",
        "        text (str): Raw text string\n",
        "        \n",
        "    Returns:\n",
        "        list: List of processed tokens\n",
        "    \"\"\"\n",
        "    # Step 1: Lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Step 2: Expand contractions (don't -> do not)\n",
        "    text = fix(text)\n",
        "    \n",
        "    # Step 3-5: Tokenization, cleaning, lemmatization\n",
        "    doc = nlp(text)\n",
        "    tokens = [\n",
        "        token.lemma_ \n",
        "        for token in doc \n",
        "        if token.is_alpha and not token.is_stop and len(token) > 2\n",
        "    ]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create corpus by preprocessing all articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "b5MCW-v8WBCu"
      },
      "outputs": [],
      "source": [
        "corpus= df['text'].apply(preprocess_text).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save preprocessed corpus for future use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = os.path.join(\"../data/processed/\", \"corpus.pkl\")\n",
        "with open(file_path, \"wb\") as f:\n",
        "    pickle.dump(corpus, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize BM25 model with preprocessed corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DJ2URawLjEiQ"
      },
      "outputs": [],
      "source": [
        "bm25 = BM25Okapi(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save BM25 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs(\"../models\", exist_ok=True)\n",
        "with open(\"../models/bm25_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(bm25, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Rj363ipYisTe"
      },
      "outputs": [],
      "source": [
        "def search_articles_bm25(query_sentence, df, top_n=5):\n",
        "    \"\"\"\n",
        "    Retrieve most relevant articles using BM25 ranking.\n",
        "    \n",
        "    BM25 (Best Match 25) considers:\n",
        "    - Term frequency: How often query terms appear in document\n",
        "    - Document length: Normalize by document length\n",
        "    - Inverse document frequency: Rare terms are more valuable\n",
        "    \n",
        "    Args:\n",
        "        query_sentence (str): User search query\n",
        "        df (DataFrame): Articles dataframe\n",
        "        top_n (int): Number of results to return\n",
        "        \n",
        "    Returns:\n",
        "        DataFrame: Top N articles with BM25 scores\n",
        "    \"\"\"\n",
        "    # Clean and preprocess query\n",
        "    query_sentence = clean_text(query_sentence)\n",
        "    query_tokens = preprocess_text(query_sentence)\n",
        "    \n",
        "    # Compute BM25 scores for all documents\n",
        "    scores = bm25.get_scores(query_tokens)\n",
        "    \n",
        "    # Get indices of top-N highest scoring documents\n",
        "    top_n_idx = np.argsort(scores)[::-1][:top_n]\n",
        "    \n",
        "    # Build results DataFrame\n",
        "    results = df.iloc[top_n_idx].copy()\n",
        "    results[\"bm25_score\"] = scores[top_n_idx]\n",
        "    \n",
        "    return results[[\"id\", \"category\", \"bm25_score\", \"text\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test BM25 search with sample query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "51NHXMA3jcKC"
      },
      "outputs": [],
      "source": [
        "sentence_query=\"Analyze China's export surge of 35% that propelled its trade surplus to a six-year high, identifying the key export sectors, the role of currency valuation, the impact on global trade balances, and the responses from trading partners.\"\n",
        "results_bm25 = search_articles_bm25(sentence_query, df,top_n=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "KqSmqVsZjddh",
        "outputId": "53cff916-3d53-4d49-ba63-86aa649ded1c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>category</th>\n",
              "      <th>bm25_score</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>426</td>\n",
              "      <td>business</td>\n",
              "      <td>59.009270</td>\n",
              "      <td>chinese exports rise 25 in 2004 exports from c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>439</td>\n",
              "      <td>business</td>\n",
              "      <td>49.612413</td>\n",
              "      <td>us trade deficit widens sharply the gap betwee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>504</td>\n",
              "      <td>business</td>\n",
              "      <td>42.571624</td>\n",
              "      <td>china now top trader with japan china overtook...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>business</td>\n",
              "      <td>33.683889</td>\n",
              "      <td>us trade gap hits record in 2004 the gap betwe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>428</td>\n",
              "      <td>business</td>\n",
              "      <td>33.157550</td>\n",
              "      <td>us trade gap ballooned in october the us trade...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  category  bm25_score  \\\n",
              "426  426  business   59.009270   \n",
              "439  439  business   49.612413   \n",
              "504  504  business   42.571624   \n",
              "23    23  business   33.683889   \n",
              "428  428  business   33.157550   \n",
              "\n",
              "                                                  text  \n",
              "426  chinese exports rise 25 in 2004 exports from c...  \n",
              "439  us trade deficit widens sharply the gap betwee...  \n",
              "504  china now top trader with japan china overtook...  \n",
              "23   us trade gap hits record in 2004 the gap betwe...  \n",
              "428  us trade gap ballooned in october the us trade...  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYm_GpKCrS5h"
      },
      "source": [
        "## SEMANTIC SEARCH WITH SPACY EMBEDDINGS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- spaCy provides pre-trained word vectors (300-dimensional GloVe embeddings)\n",
        "- that capture semantic meaning beyond exact keyword matches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download large spaCy model with word vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m spacy download en_core_web_lg "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "cUjfc3RasvCW"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "import os\n",
        "import faiss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load large spaCy model with word vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "--sstYL4jeV-"
      },
      "outputs": [],
      "source": [
        "def compute_spacy_doc_vectors(df, text_col=\"text\", save_path=\"../data/embeddings/spacy_doc_vectors.npy\"):\n",
        "    \"\"\"\n",
        "    Compute and cache document embeddings using spaCy word vectors.\n",
        "    \n",
        "    spaCy's doc.vector averages the word vectors of all tokens,\n",
        "    creating a single dense representation of the document's meaning.\n",
        "    \n",
        "    Args:\n",
        "        df (DataFrame): Articles dataframe\n",
        "        text_col (str): Name of text column\n",
        "        save_path (str): Path to cache embeddings\n",
        "        \n",
        "    Returns:\n",
        "        ndarray: Matrix of document vectors (n_docs x 300)\n",
        "    \"\"\"\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "    \n",
        "    # Load from cache if exists\n",
        "    if os.path.exists(save_path):\n",
        "        return np.load(save_path)\n",
        "    \n",
        "    # Compute document vectors (averaging word embeddings)\n",
        "    doc_vectors = np.vstack([nlp(text).vector for text in df[text_col]])\n",
        "    \n",
        "    # Cache for future use\n",
        "    np.save(save_path, doc_vectors)\n",
        "    \n",
        "    return doc_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_faiss_index(doc_vectors, save_path=\"../data/embeddings/faiss_index.bin\"):\n",
        "    \"\"\"\n",
        "    Build FAISS index for fast approximate nearest neighbor search.\n",
        "    \n",
        "    FAISS (Facebook AI Similarity Search) enables efficient similarity \n",
        "    search in high-dimensional spaces using optimized algorithms.\n",
        "    \n",
        "    Args:\n",
        "        doc_vectors (ndarray): Document embedding matrix\n",
        "        save_path (str): Path to save FAISS index\n",
        "        \n",
        "    Returns:\n",
        "        faiss.Index: FAISS index object\n",
        "    \"\"\"\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "    \n",
        "    # Ensure float32 dtype (required by FAISS)\n",
        "    doc_vectors = doc_vectors.astype(\"float32\")\n",
        "    \n",
        "    # Normalize vectors for cosine similarity\n",
        "    # After normalization, inner product = cosine similarity\n",
        "    faiss.normalize_L2(doc_vectors)\n",
        "    \n",
        "    # Create FAISS index using inner product (cosine similarity)\n",
        "    index = faiss.IndexFlatIP(doc_vectors.shape[1])\n",
        "    index.add(doc_vectors)\n",
        "    \n",
        "    # Persist index to disk\n",
        "    faiss.write_index(index, save_path)\n",
        "    \n",
        "    return index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_articles_spacy(query, df, index, top_n=5):\n",
        "    \"\"\"\n",
        "    Perform semantic search using FAISS + spaCy embeddings.\n",
        "    \n",
        "    This approach finds articles semantically similar to the query,\n",
        "    even if they don't share exact keywords.\n",
        "    \n",
        "    Args:\n",
        "        query (str): User search query\n",
        "        df (DataFrame): Articles dataframe\n",
        "        index (faiss.Index): Pre-built FAISS index\n",
        "        top_n (int): Number of results to return\n",
        "        \n",
        "    Returns:\n",
        "        DataFrame: Top N most similar articles with similarity scores\n",
        "    \"\"\"\n",
        "    # Clean query and convert to vector\n",
        "    query = clean_text(query)\n",
        "    query_vec = nlp(query).vector.astype(\"float32\").reshape(1, -1)\n",
        "    faiss.normalize_L2(query_vec)\n",
        "    \n",
        "    # Perform fast similarity search\n",
        "    distances, indices = index.search(query_vec, top_n)\n",
        "    \n",
        "    # Build results DataFrame\n",
        "    results = df.iloc[indices[0]].copy()\n",
        "    results[\"similarity\"] = distances[0]\n",
        "    \n",
        "    return results[[\"id\", \"category\", \"similarity\", \"text\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute embeddings and build FAISS index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "doc_vectors_spacy = compute_spacy_doc_vectors(df)\n",
        "index_spacy = build_faiss_index(doc_vectors_spacy,save_path=\"../data/embeddings/faiss_index_spacy.bin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test spaCy semantic search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentence_query=\"Analyze China's export surge of 35% that propelled its trade surplus to a six-year high, identifying the key export sectors, the role of currency valuation, the impact on global trade balances, and the responses from trading partners.\"\n",
        "results_spacy = search_articles_spacy(sentence_query, df,index_spacy, top_n=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "Qo4tXha_uQb5",
        "outputId": "a0e21e28-cd96-4485-eee1-e170ff834450"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>category</th>\n",
              "      <th>similarity</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>66</td>\n",
              "      <td>business</td>\n",
              "      <td>0.920587</td>\n",
              "      <td>fao warns on impact of subsidies billions of f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>171</td>\n",
              "      <td>business</td>\n",
              "      <td>0.911932</td>\n",
              "      <td>newest eu members underpin growth the european...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>426</td>\n",
              "      <td>business</td>\n",
              "      <td>0.905781</td>\n",
              "      <td>chinese exports rise 25 in 2004 exports from c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>282</td>\n",
              "      <td>business</td>\n",
              "      <td>0.905367</td>\n",
              "      <td>stock market eyes japan recovery japanese shar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>339</td>\n",
              "      <td>business</td>\n",
              "      <td>0.905277</td>\n",
              "      <td>venezuela and china sign oil deal venezuelan p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  category  similarity  \\\n",
              "66    66  business    0.920587   \n",
              "171  171  business    0.911932   \n",
              "426  426  business    0.905781   \n",
              "282  282  business    0.905367   \n",
              "339  339  business    0.905277   \n",
              "\n",
              "                                                  text  \n",
              "66   fao warns on impact of subsidies billions of f...  \n",
              "171  newest eu members underpin growth the european...  \n",
              "426  chinese exports rise 25 in 2004 exports from c...  \n",
              "282  stock market eyes japan recovery japanese shar...  \n",
              "339  venezuela and china sign oil deal venezuelan p...  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x94QCSCyvfIE"
      },
      "source": [
        "## SEMANTIC SEARCH WITH TRANSFORMER EMBEDDINGS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Transformer models (BERT-based) provide state-of-the-art contextual \n",
        "- embeddings that capture nuanced semantic meanin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "C4MlrL8Qwu6G"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Initialize sentence transformer model\n",
        "- all-MiniLM-L6-v2: Fast and efficient model with 384-dimensional embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "SSd5pPdTxYpy"
      },
      "outputs": [],
      "source": [
        "def compute_transformer_doc_vectors(df, text_col=\"text\", cache_path=\"../data/embeddings/transformer_doc_vectors.npy\"):\n",
        "    \"\"\"\n",
        "    Compute and cache SentenceTransformer embeddings for each document.\n",
        "    \n",
        "    SentenceTransformers produce high-quality sentence embeddings using\n",
        "    BERT-based models fine-tuned for semantic similarity tasks.\n",
        "    \n",
        "    Args:\n",
        "        df (DataFrame): Articles dataframe\n",
        "        text_col (str): Name of text column\n",
        "        cache_path (str): Path to cache embeddings\n",
        "        \n",
        "    Returns:\n",
        "        ndarray: Matrix of document vectors (n_docs x 384)\n",
        "    \"\"\"\n",
        "    # Load from cache if available\n",
        "    if os.path.exists(cache_path):\n",
        "        embeddings = np.load(cache_path)\n",
        "    else:\n",
        "        # Encode all documents (batch processing with progress bar)\n",
        "        embeddings = embedder.encode(\n",
        "            df[text_col].tolist(), \n",
        "            convert_to_numpy=True, \n",
        "            show_progress_bar=True\n",
        "        )\n",
        "        # Cache embeddings\n",
        "        np.save(cache_path, embeddings)\n",
        "    \n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_articles_semantic(query, df, index, top_n=5):\n",
        "    \"\"\"\n",
        "    Perform semantic search using SentenceTransformer embeddings + FAISS.\n",
        "    \n",
        "    This approach provides the most sophisticated semantic understanding,\n",
        "    capturing context and meaning beyond individual words.\n",
        "    \n",
        "    Args:\n",
        "        query (str): User search query\n",
        "        df (DataFrame): Articles dataframe\n",
        "        index (faiss.Index): Pre-built FAISS index\n",
        "        top_n (int): Number of results to return\n",
        "        \n",
        "    Returns:\n",
        "        DataFrame: Top N most similar articles with similarity scores\n",
        "    \"\"\"\n",
        "    # Clean and encode query\n",
        "    query = clean_text(query)\n",
        "    query_vec = embedder.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
        "    faiss.normalize_L2(query_vec)\n",
        "    \n",
        "    # Perform similarity search\n",
        "    distances, indices = index.search(query_vec, top_n)\n",
        "    \n",
        "    # Build results\n",
        "    results = df.iloc[indices[0]].copy()\n",
        "    results[\"similarity\"] = distances[0]\n",
        "    \n",
        "    return results[[\"id\", \"category\", \"similarity\", \"text\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute transformer embeddings and build FAISS index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "doc_vectors_semantic = compute_transformer_doc_vectors(df)\n",
        "index_semantic = build_faiss_index(doc_vectors_semantic,save_path=\"../data/embeddings/faiss_index_semantic.bin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test transformer-based semantic search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "6ebd81c7e1f24cb398ff056be7dc9e69",
            "c2a9909480fe41d4a0abebcc654ee587",
            "f9600d9d00ed4f7b859480eb066602ab",
            "74e52d2c7c954b2582d1dc29262495ae",
            "f99517e96c2841598d035c7c8280577c",
            "a9bbed3c30af498b8e463eea5fe0e677",
            "9118401fcb2549c8823aef86cd048d52",
            "13ca2366d3dd42c2a88df2bbd5870d48",
            "4d0d91767dd84a3997a137cac1027a8e",
            "e0beff7134034799941e592c6375269f",
            "caed902c52934685a5420c94b56f10da"
          ]
        },
        "id": "FFtdtgBB21zb",
        "outputId": "ac1f6ae7-a82b-48a2-c48b-c486b3d1423b"
      },
      "outputs": [],
      "source": [
        "sentence_query=\"Analyze China's export surge of 35% that propelled its trade surplus to a six-year high, identifying the key export sectors, the role of currency valuation, the impact on global trade balances, and the responses from trading partners.\"\n",
        "results_semantic = search_articles_semantic(sentence_query, df,index_semantic, top_n=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "cSJ-LDwQ94H9",
        "outputId": "a3e9066b-6fe2-43ec-9249-678ecde19d31"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>category</th>\n",
              "      <th>similarity</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>426</td>\n",
              "      <td>business</td>\n",
              "      <td>0.649032</td>\n",
              "      <td>chinese exports rise 25 in 2004 exports from c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>428</td>\n",
              "      <td>business</td>\n",
              "      <td>0.647292</td>\n",
              "      <td>us trade gap ballooned in october the us trade...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>business</td>\n",
              "      <td>0.630536</td>\n",
              "      <td>china keeps tight rein on credit chinas effort...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>504</td>\n",
              "      <td>business</td>\n",
              "      <td>0.610793</td>\n",
              "      <td>china now top trader with japan china overtook...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>business</td>\n",
              "      <td>0.591622</td>\n",
              "      <td>us trade gap hits record in 2004 the gap betwe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  category  similarity  \\\n",
              "426  426  business    0.649032   \n",
              "428  428  business    0.647292   \n",
              "15    15  business    0.630536   \n",
              "504  504  business    0.610793   \n",
              "23    23  business    0.591622   \n",
              "\n",
              "                                                  text  \n",
              "426  chinese exports rise 25 in 2004 exports from c...  \n",
              "428  us trade gap ballooned in october the us trade...  \n",
              "15   china keeps tight rein on credit chinas effort...  \n",
              "504  china now top trader with japan china overtook...  \n",
              "23   us trade gap hits record in 2004 the gap betwe...  "
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_semantic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC_IBDEWiT0s"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Compare all three search approaches using standard information retrieval\n",
        "- metrics: Precision@K, NDCG@K, and Mean Average Precision (MAP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import ndcg_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_ground_truth(csv_path):\n",
        "    \"\"\"\n",
        "    Load ground truth relevance judgments from CSV.\n",
        "    \n",
        "    Ground truth format: Each row contains a query and 5 relevant doc IDs\n",
        "    ordered by relevance (id_1 is most relevant).\n",
        "    \n",
        "    Args:\n",
        "        csv_path (str): Path to evaluation CSV\n",
        "        \n",
        "    Returns:\n",
        "        dict: Mapping of query -> list of relevant doc IDs\n",
        "    \"\"\"\n",
        "    df_eval = pd.read_csv(csv_path)\n",
        "    ground_truth = {}\n",
        "    \n",
        "    for _, row in df_eval.iterrows():\n",
        "        # Extract relevant IDs in order of decreasing relevance\n",
        "        relevant_ids = []\n",
        "        for col in [\"id_1\", \"id_2\", \"id_3\", \"id_4\", \"id_5\"]:\n",
        "            if pd.notna(row[col]):\n",
        "                relevant_ids.append(int(row[col]))\n",
        "        ground_truth[row[\"query\"]] = relevant_ids\n",
        "    \n",
        "    return ground_truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "def precision_at_k(retrieved_ids, relevant_ids, k=5):\n",
        "    \"\"\"\n",
        "    Calculate Precision@K metric.\n",
        "    \n",
        "    Precision@K measures the proportion of relevant documents \n",
        "    in the top-K retrieved results.\n",
        "    \n",
        "    Formula: P@K = (# relevant docs in top-K) / K\n",
        "    \n",
        "    Args:\n",
        "        retrieved_ids (list): Retrieved document IDs (in rank order)\n",
        "        relevant_ids (list): Ground truth relevant document IDs\n",
        "        k (int): Cut-off rank position\n",
        "        \n",
        "    Returns:\n",
        "        float: Precision score between 0 and 1\n",
        "    \"\"\"\n",
        "    if not retrieved_ids:\n",
        "        return 0.0\n",
        "    \n",
        "    retrieved_k = retrieved_ids[:k]\n",
        "    relevant_set = set(relevant_ids)\n",
        "    hits = sum(1 for doc_id in retrieved_k if doc_id in relevant_set)\n",
        "    \n",
        "    return hits / min(k, len(retrieved_k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ndcg_at_k(retrieved_ids, relevant_ids, k=5):\n",
        "    \"\"\"\n",
        "    Compute Normalized Discounted Cumulative Gain (NDCG@K).\n",
        "    \n",
        "    NDCG@K measures how well the retrieved results are ranked,\n",
        "    giving higher weight to relevant documents at top positions.\n",
        "    \n",
        "    Formula: NDCG = DCG / IDCG\n",
        "    - DCG: Sum of (relevance / log2(rank+1))\n",
        "    - IDCG: DCG of ideal ranking\n",
        "    \n",
        "    Args:\n",
        "        retrieved_ids (list): Retrieved document IDs (in rank order)\n",
        "        relevant_ids (list): Ground truth relevant IDs (in relevance order)\n",
        "        k (int): Cut-off rank position\n",
        "        \n",
        "    Returns:\n",
        "        float: NDCG score between 0 and 1\n",
        "    \"\"\"\n",
        "    if not retrieved_ids or not relevant_ids:\n",
        "        return 0.0\n",
        "    \n",
        "    # Assign decreasing relevance scores (id_1 = most relevant)\n",
        "    relevance_map = {\n",
        "        doc_id: len(relevant_ids) - i \n",
        "        for i, doc_id in enumerate(relevant_ids)\n",
        "    }\n",
        "    \n",
        "    # Build relevance vector for retrieved docs\n",
        "    retrieved_k = retrieved_ids[:k]\n",
        "    y_true = np.array([[relevance_map.get(doc_id, 0) for doc_id in retrieved_k]])\n",
        "    y_score = np.array([[k - i for i in range(len(retrieved_k))]])\n",
        "    \n",
        "    if np.sum(y_true) == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    return float(ndcg_score(y_true, y_score, k=k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "def average_precision(retrieved_ids, relevant_ids):\n",
        "    \"\"\"\n",
        "    Compute Average Precision (AP).\n",
        "    \n",
        "    AP is the average of precision values computed at each position\n",
        "    where a relevant document is retrieved.\n",
        "    \n",
        "    Formula: AP = (1/|relevant|) * Î£(P@k * rel(k))\n",
        "    where rel(k) = 1 if doc at position k is relevant, else 0\n",
        "    \n",
        "    Args:\n",
        "        retrieved_ids (list): Retrieved document IDs (in rank order)\n",
        "        relevant_ids (list): Ground truth relevant document IDs\n",
        "        \n",
        "    Returns:\n",
        "        float: Average Precision score between 0 and 1\n",
        "    \"\"\"\n",
        "    if not relevant_ids:\n",
        "        return 0.0\n",
        "    \n",
        "    relevant_set = set(relevant_ids)\n",
        "    score = 0.0\n",
        "    hits = 0\n",
        "    \n",
        "    # For each retrieved document\n",
        "    for i, doc_id in enumerate(retrieved_ids):\n",
        "        if doc_id in relevant_set:\n",
        "            hits += 1\n",
        "            # Add precision at this position\n",
        "            score += hits / (i + 1)\n",
        "    \n",
        "    return score / len(relevant_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(search_function, ground_truth, df, model_name=\"Model\", k=5, **kwargs):\n",
        "    \"\"\"\n",
        "    Evaluate a search model using all metrics.\n",
        "    \n",
        "    Computes Precision@K, NDCG@K, and MAP for all queries in ground truth\n",
        "    and returns averaged results.\n",
        "    \n",
        "    Args:\n",
        "        search_function: Function that takes (query, df, top_n, **kwargs)\n",
        "        ground_truth: Dict mapping queries to relevant doc IDs\n",
        "        df: Articles DataFrame\n",
        "        model_name: Name for display in results\n",
        "        k: Number of results to evaluate\n",
        "        **kwargs: Additional args for search_function (e.g., index, bm25)\n",
        "        \n",
        "    Returns:\n",
        "        dict: Evaluation metrics averaged across all queries\n",
        "    \"\"\"\n",
        "    all_retrieved = {}\n",
        "    precisions = []\n",
        "    ndcgs = []\n",
        "    aps = []\n",
        "    \n",
        "    # Evaluate each query\n",
        "    for query, relevant_ids in ground_truth.items():\n",
        "        # Retrieve results using specified search function\n",
        "        results = search_function(query, df, top_n=k, **kwargs)\n",
        "        retrieved_ids = results[\"id\"].tolist()\n",
        "        all_retrieved[query] = retrieved_ids\n",
        "        \n",
        "        # Calculate metrics for this query\n",
        "        prec = precision_at_k(retrieved_ids, relevant_ids, k=k)\n",
        "        ndcg = ndcg_at_k(retrieved_ids, relevant_ids, k=k)\n",
        "        ap = average_precision(retrieved_ids, relevant_ids)\n",
        "        \n",
        "        precisions.append(prec)\n",
        "        ndcgs.append(ndcg)\n",
        "        aps.append(ap)\n",
        "    \n",
        "    # Return averaged metrics\n",
        "    results = {\n",
        "        \"Model\": model_name,\n",
        "        f\"Precision@{k}\": np.mean(precisions),\n",
        "        f\"NDCG@{k}\": np.mean(ndcgs),\n",
        "        \"MAP\": np.mean(aps)\n",
        "    }\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_complete_evaluation(ground_truth, df, bm25, index_spacy, index_semantic, k=5):\n",
        "    \"\"\"\n",
        "    Run evaluation for all three models and compare results.\n",
        "    \n",
        "    This function evaluates:\n",
        "    1. Lexical Search (BM25)\n",
        "    2. Semantic Search (spaCy embeddings)\n",
        "    3. Semantic Search (Transformer embeddings)\n",
        "    \n",
        "    Args:\n",
        "        ground_truth: Dict of query -> relevant doc IDs\n",
        "        df: Articles DataFrame\n",
        "        bm25: BM25 model object\n",
        "        index_spacy: FAISS index for spaCy embeddings\n",
        "        index_semantic: FAISS index for transformer embeddings\n",
        "        k: Number of results to evaluate\n",
        "        \n",
        "    Returns:\n",
        "        DataFrame: Comparison of all models' performance\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    \n",
        "    # 1. Evaluate BM25 (Lexical Search)\n",
        "    bm25_results = evaluate_model(search_articles_bm25,ground_truth,df,model_name=\"Lexical model\",k=k)\n",
        "    results.append(bm25_results)\n",
        "    \n",
        "    # 2. Evaluate spaCy (Semantic Search with GloVe)\n",
        "    spacy_results = evaluate_model( search_articles_spacy, ground_truth,df,model_name=\"spaCy model\", k=k,index=index_spacy)\n",
        "    results.append(spacy_results)\n",
        "    \n",
        "    # 3. Evaluate Transformer (Semantic Search with BERT)\n",
        "    transformer_results = evaluate_model( search_articles_semantic,ground_truth, df, model_name=\"semantic model\",k=k, index=index_semantic)\n",
        "    results.append(transformer_results)\n",
        "    \n",
        "    # Create comparison DataFrame\n",
        "    comparison_df = pd.DataFrame(results)\n",
        "    \n",
        "    return comparison_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RUN COMPLETE EVALUATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load ground truth relevance judgments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "ground_truth = load_ground_truth(\"../data/evaluation/evaluation.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate all three models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation_results = run_complete_evaluation(ground_truth=ground_truth,df=df,bm25=bm25,\n",
        "                                             index_spacy=index_spacy,index_semantic=index_semantic,k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display comparison results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Precision@5</th>\n",
              "      <th>NDCG@5</th>\n",
              "      <th>MAP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lexical model</td>\n",
              "      <td>0.228571</td>\n",
              "      <td>0.888587</td>\n",
              "      <td>0.202597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spaCy model</td>\n",
              "      <td>0.187013</td>\n",
              "      <td>0.612753</td>\n",
              "      <td>0.141515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>semantic model</td>\n",
              "      <td>0.244156</td>\n",
              "      <td>0.932487</td>\n",
              "      <td>0.217532</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Model  Precision@5    NDCG@5       MAP\n",
              "0   Lexical model     0.228571  0.888587  0.202597\n",
              "1     spaCy model     0.187013  0.612753  0.141515\n",
              "2  semantic model     0.244156  0.932487  0.217532"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluation_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RESULTS INTERPRETATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Precision@5: Proportion of relevant docs in top 5 results\n",
        "- NDCG@5: Quality of ranking (1.0 = perfect ranking)\n",
        "- MAP: Mean Average Precision across all queries\n",
        "\n",
        "- Higher values indicate better performance.\n",
        "- tansformer based Semantic models typically outperform lexical and spacy search for complex queries.\n",
        "- lexical search outperform spacy search."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "nYm_GpKCrS5h",
        "x94QCSCyvfIE"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "semsearch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
